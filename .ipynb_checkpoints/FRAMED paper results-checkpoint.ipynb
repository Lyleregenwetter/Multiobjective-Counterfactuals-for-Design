{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01605004",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogluon'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabularDataset, TabularPredictor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import load_data\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620fb269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Material=Steel  Material=Aluminum  Material=Titanium  SSB_Include  \\\n",
      "1                       1                  0                  0            0   \n",
      "2                       0                  1                  0            0   \n",
      "4                       1                  0                  0            0   \n",
      "5                       1                  0                  0            0   \n",
      "7                       0                  1                  0            0   \n",
      "...                   ...                ...                ...          ...   \n",
      "Gen 10800               0                  0                  1            1   \n",
      "Gen 10801               1                  0                  0            0   \n",
      "Gen 10802               1                  0                  0            1   \n",
      "Gen 10803               0                  0                  1            1   \n",
      "Gen 10804               1                  0                  0            1   \n",
      "\n",
      "           CSB_Include  CS Length   BB Drop    Stack      SS E   ST Angle  \\\n",
      "1                    0   0.430000  0.067000  0.56560  0.045000  72.500000   \n",
      "2                    0   0.350000 -0.014500  0.56560  0.045000  71.499976   \n",
      "4                    0   0.375000  0.050000  0.56560  0.040000  73.500000   \n",
      "5                    0   0.431790  0.024000  0.56560  0.041000  72.500000   \n",
      "7                    0   0.425000  0.029863  0.56560  0.065000  72.034832   \n",
      "...                ...        ...       ...      ...       ...        ...   \n",
      "Gen 10800            1   0.404343  0.070217  0.60513  0.046062  74.004833   \n",
      "Gen 10801            0   0.375302  0.004917  0.56559  0.044787  74.136556   \n",
      "Gen 10802            1   0.381514 -0.005223  0.50384  0.044883  74.311423   \n",
      "Gen 10803            1   0.408831  0.046496  0.56566  0.210201  73.993603   \n",
      "Gen 10804            1   0.466464 -0.018791  0.54365  0.216356  82.233882   \n",
      "\n",
      "           ...  CSB Offset      SS Z  SS Thickness  CS Thickness  \\\n",
      "1          ...    0.350000  0.007000      0.004851      0.001494   \n",
      "2          ...    0.350000  0.008000      0.000591      0.008614   \n",
      "4          ...    0.350000  0.010600      0.008779      0.001868   \n",
      "5          ...    0.350000  0.008000      0.000789      0.007232   \n",
      "7          ...    0.350000  0.011200      0.000665      0.001475   \n",
      "...        ...         ...       ...           ...           ...   \n",
      "Gen 10800  ...    0.349888  0.009524      0.001493      0.000268   \n",
      "Gen 10801  ...    0.300055  0.009080      0.001779      0.002396   \n",
      "Gen 10802  ...    0.350045  0.009202      0.002771      0.003864   \n",
      "Gen 10803  ...    0.350050  0.009095      0.002597      0.001750   \n",
      "Gen 10804  ...    0.349972  0.009195      0.000580      0.001633   \n",
      "\n",
      "           TT Thickness  BB Thickness  HT Thickness  ST Thickness  \\\n",
      "1              0.002192      0.001248      0.004916      0.002080   \n",
      "2              0.000538      0.003519      0.001257      0.000895   \n",
      "4              0.002585      0.003423      0.001143      0.002562   \n",
      "5              0.002530      0.005867      0.006491      0.000732   \n",
      "7              0.001510      0.005078      0.005528      0.009230   \n",
      "...                 ...           ...           ...           ...   \n",
      "Gen 10800      0.002937      0.003064      0.003879      0.002326   \n",
      "Gen 10801      0.000531      0.002898      0.001015      0.002106   \n",
      "Gen 10802      0.003597      0.002072      0.002901      0.001584   \n",
      "Gen 10803      0.001221      0.001356      0.003355      0.002262   \n",
      "Gen 10804      0.002405      0.001930      0.003670      0.003564   \n",
      "\n",
      "           DT Thickness  DT Length  \n",
      "1              0.001295   0.664021  \n",
      "2              0.002477   0.572492  \n",
      "4              0.001762   0.573904  \n",
      "5              0.007557   0.636179  \n",
      "7              0.000573   0.688292  \n",
      "...                 ...        ...  \n",
      "Gen 10800      0.002236   0.661986  \n",
      "Gen 10801      0.002719   0.609958  \n",
      "Gen 10802      0.001936   0.642023  \n",
      "Gen 10803      0.001081   0.653353  \n",
      "Gen 10804      0.003771   0.721923  \n",
      "\n",
      "[14851 rows x 39 columns]\n",
      "           Sim 1 Dropout X Disp. Magnitude  Sim 1 Dropout Y Disp. Magnitude  \\\n",
      "1                                 0.294326                         0.285729   \n",
      "2                                -0.020621                        -0.311043   \n",
      "4                                -0.524406                        -0.557748   \n",
      "5                                -0.671856                        -0.632974   \n",
      "7                                 0.302733                         0.343482   \n",
      "...                                    ...                              ...   \n",
      "Gen 10800                         0.772243                         0.564124   \n",
      "Gen 10801                        -0.646828                        -0.626458   \n",
      "Gen 10802                        -0.636869                        -0.575636   \n",
      "Gen 10803                         0.064098                         0.041097   \n",
      "Gen 10804                        -0.616756                        -0.495642   \n",
      "\n",
      "           Sim 1 Bottom Bracket X Disp. Magnitude  \\\n",
      "1                                        0.325527   \n",
      "2                                       -0.163378   \n",
      "4                                       -0.528827   \n",
      "5                                       -0.677410   \n",
      "7                                        0.194970   \n",
      "...                                           ...   \n",
      "Gen 10800                                0.778924   \n",
      "Gen 10801                               -0.664628   \n",
      "Gen 10802                               -0.663153   \n",
      "Gen 10803                               -0.004416   \n",
      "Gen 10804                               -0.658673   \n",
      "\n",
      "           Sim 1 Bottom Bracket Y Disp. Magnitude  \\\n",
      "1                                        0.278309   \n",
      "2                                       -0.400131   \n",
      "4                                       -0.614545   \n",
      "5                                       -0.683180   \n",
      "7                                        0.502989   \n",
      "...                                           ...   \n",
      "Gen 10800                                0.680151   \n",
      "Gen 10801                               -0.648804   \n",
      "Gen 10802                               -0.568553   \n",
      "Gen 10803                                0.071228   \n",
      "Gen 10804                               -0.530950   \n",
      "\n",
      "           Sim 2 Bottom Bracket Z Disp. Magnitude  \\\n",
      "1                                        0.137035   \n",
      "2                                        0.174547   \n",
      "4                                        0.215184   \n",
      "5                                       -0.644450   \n",
      "7                                        1.725796   \n",
      "...                                           ...   \n",
      "Gen 10800                                1.828952   \n",
      "Gen 10801                               -0.621240   \n",
      "Gen 10802                               -0.617645   \n",
      "Gen 10803                                0.934151   \n",
      "Gen 10804                               -0.340452   \n",
      "\n",
      "           Sim 3 Bottom Bracket Y Disp. Magnitude  \\\n",
      "1                                       -0.057174   \n",
      "2                                       -0.259392   \n",
      "4                                       -0.614860   \n",
      "5                                       -0.697120   \n",
      "7                                        3.071308   \n",
      "...                                           ...   \n",
      "Gen 10800                                0.309305   \n",
      "Gen 10801                               -0.491469   \n",
      "Gen 10802                               -0.192677   \n",
      "Gen 10803                                1.220127   \n",
      "Gen 10804                               -0.111906   \n",
      "\n",
      "           Sim 3 Bottom Bracket X Rot. Magnitude  \\\n",
      "1                                      -0.066910   \n",
      "2                                       0.443392   \n",
      "4                                       0.069430   \n",
      "5                                      -0.612272   \n",
      "7                                       2.036627   \n",
      "...                                          ...   \n",
      "Gen 10800                               0.790086   \n",
      "Gen 10801                              -0.450611   \n",
      "Gen 10802                              -0.405814   \n",
      "Gen 10803                               0.751132   \n",
      "Gen 10804                              -0.357121   \n",
      "\n",
      "           Sim 1 Safety Factor (Inverted)  Sim 3 Safety Factor (Inverted)  \\\n",
      "1                                0.152089                       -0.055607   \n",
      "2                               -0.092752                        0.063785   \n",
      "4                               -0.146008                       -0.103372   \n",
      "5                               -0.207557                       -0.205490   \n",
      "7                               -0.036968                        0.511256   \n",
      "...                                   ...                             ...   \n",
      "Gen 10800                       -0.156851                       -0.227774   \n",
      "Gen 10801                       -0.272115                       -0.099457   \n",
      "Gen 10802                       -0.283704                       -0.090777   \n",
      "Gen 10803                       -0.282988                       -0.129737   \n",
      "Gen 10804                       -0.259286                       -0.090514   \n",
      "\n",
      "           Model Mass Magnitude  \n",
      "1                     -0.191143  \n",
      "2                     -1.453684  \n",
      "4                     -0.929186  \n",
      "5                      0.880331  \n",
      "7                     -1.086535  \n",
      "...                         ...  \n",
      "Gen 10800             -0.955411  \n",
      "Gen 10801             -0.562038  \n",
      "Gen 10802              0.026149  \n",
      "Gen 10803             -1.064057  \n",
      "Gen 10804              0.280905  \n",
      "\n",
      "[14851 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "x_scaled, y, _, xscaler = load_data.load_framed_dataset(\"r\", onehot = True, scaled = False, augmented = True)\n",
    "    \n",
    "#Filter top n% of values\n",
    "# q = y.quantile(.95)\n",
    "# for col in y.columns:\n",
    "#     y=y[y[col] <= q[col]]\n",
    "# x_scaled=x_scaled.loc[y.index]\n",
    "    \n",
    "yscaler = StandardScaler()\n",
    "yscaler.fit(y)\n",
    "y_scaled = yscaler.transform(y)\n",
    "y_scaled=pd.DataFrame(y_scaled, columns=y.columns, index=y.index)\n",
    "\n",
    "print(x_scaled)\n",
    "print(y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "504d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "#             print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15acfad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_scaled=pd.DataFrame(x_scaled, columns=x.columns, index=x.index)\n",
    "\n",
    "# print(data)\n",
    "continuous_features=['CS Length', 'BB Drop', 'Stack', 'SS E',\n",
    "       'ST Angle', 'BB OD', 'TT OD', 'HT OD', 'DT OD', 'CS OD', 'SS OD',\n",
    "       'ST OD', 'CS F', 'HT LX', 'ST UX', 'HT UX', 'HT Angle', 'HT Length',\n",
    "       'ST Length', 'BB Length', 'Dropout Offset', 'SSB OD', 'CSB OD',\n",
    "       'SSB Offset', 'CSB Offset', 'SS Z', 'SS Thickness', 'CS Thickness',\n",
    "       'TT Thickness', 'BB Thickness', 'HT Thickness', 'ST Thickness',\n",
    "       'DT Thickness', 'DT Length']\n",
    "categorical = x_scaled.columns.difference(continuous_features)\n",
    "for col in categorical:\n",
    "    x_scaled[col] = x_scaled[col].astype(str)\n",
    "xdata=x_scaled\n",
    "ydata=y_scaled\n",
    "data=pd.concat([xdata, ydata], axis=1)\n",
    "data_train, data_test, y_train, y_test=train_test_split(data, ydata, test_size=0.2, random_state=2021)\n",
    "x_train, x_test, y_train, y_test=train_test_split(xdata, ydata, test_size=0.2, random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637e705d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221019_001715\\Predictor_Sim 1 Dropout X Disp.\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.8.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    11880\n",
      "Train Data Columns: 39\n",
      "Label Column: Sim 1 Dropout X Disp.\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (14.664168867583603, -0.8695634632320092, -0.00256, 0.99583)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18879.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.68 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 34 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
      "\t\t('object', []) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 34 | ['CS Length', 'BB Drop', 'Stack', 'SS E', 'ST Angle', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['Material=Steel', 'Material=Aluminum', 'Material=Titanium', 'SSB_Include', 'CSB_Include']\n",
      "\t0.1s = Fit runtime\n",
      "\t39 features in original data used to generate 39 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.29 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 10692, Val Rows: 1188\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: Sim 1 Dropout X Disp. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.0725\t = Validation score   (root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.0407\t = Validation score   (root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.381692\n",
      "[2000]\tvalid_set's rmse: 0.380169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.3794\t = Validation score   (root_mean_squared_error)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.389907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34416/1670621295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultilabelPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34416/3418856608.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, tuning_data, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mtuning_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuning_data_og\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_to_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Fitting TabularPredictor for label: {label} ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuning_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuning_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msave_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    811\u001b[0m         }\n\u001b[0;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 813\u001b[1;33m         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\n\u001b[0m\u001b[0;32m    814\u001b[0m                           \u001b[0mholdout_frac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mholdout_frac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bag_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_bag_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_bag_sets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m                           \u001b[0mnum_stack_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_stack_levels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Learner is already fit.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         trainer.fit(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m                                      'Bagging/Stacking with a held-out validation set (blend stacking) is not yet supported.')\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         self._train_multi_and_ensemble(X=X,\n\u001b[0m\u001b[0;32m     86\u001b[0m                                        \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                        \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   1527\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_rows_train\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\n\u001b[0m\u001b[0;32m   1530\u001b[0m                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\n\u001b[0;32m   1531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_limit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time_limit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time_limit'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time_limit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[0;32m    288\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_model_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_model_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name_suffix'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name_suffix'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name_suffix'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name_suffix'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,\n\u001b[0m\u001b[0;32m    398\u001b[0m                                                 level=level, infer_limit=infer_limit, infer_limit_batch_size=infer_limit_batch_size, base_model_names=base_model_names, **core_kwargs)\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m         return self._train_multi(X=X_init, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled,\n\u001b[0m\u001b[0;32m    488\u001b[0m                                  models=models, level=level, stack_name=stack_name, fit_kwargs=fit_kwargs, **kwargs)\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m             model_names_trained = self._train_multi_initial(X=X, y=y, models=models, k_fold=k_fold, n_repeats=n_repeats_initial, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[0;32m   1502\u001b[0m                                                             feature_prune_kwargs=feature_prune_kwargs, time_limit=time_limit, **kwargs)\n\u001b[0;32m   1503\u001b[0m             \u001b[0mn_repeat_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_repeats_initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbagged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m             models = self._train_multi_fold(models=models, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[0;32m   1388\u001b[0m                                             time_limit=time_limit, time_split=time_split, time_ratio=time_ratio, **fit_args)\n\u001b[0;32m   1389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             \u001b[0mmodel_name_trained_lst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_single_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1294\u001b[0m                 \u001b[0mbagged_model_fit_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_bagged_model_fit_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_fold_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_fold_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_fold_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repeat_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_repeat_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m             \u001b[0mmodel_names_trained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstack_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_names_trained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[1;34m(self, X, y, model, X_val, y_val, stack_name, level, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_w_pseudo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_w_pseudo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[1;34m(self, X, y, model, X_val, y_val, **model_fit_kwargs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \"\"\"\n\u001b[1;32m-> 1032\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_fit_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\autogluon\\tabular\\models\\lgb\\lgb_model.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_column in param dict is overridden.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'gpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf27\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3020\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3021\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels=y.columns\n",
    "predictor = MultilabelPredictor(labels=labels)\n",
    "predictor.fit(train_data=data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26a851c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.5911548521600816\n",
      "MSE: 35.511004674559004\n",
      "MAE: 0.269658398772196\n"
     ]
    }
   ],
   "source": [
    "predictions=predictor.predict(x_test)\n",
    "train_predictions=predictor.predict(x_train)\n",
    "r2=sklearn.metrics.r2_score(y_test, predictions)\n",
    "mse=sklearn.metrics.mean_squared_error(y_test, predictions)\n",
    "mae=sklearn.metrics.mean_absolute_error(y_test, predictions)\n",
    "print(\"R2: \" + str(r2))\n",
    "print(\"MSE: \" + str(mse))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "808346dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(predictor.predict_proba(x[100:101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fb06682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Mass\n"
     ]
    }
   ],
   "source": [
    "predidx=9\n",
    "outcome_name=y.columns[predidx]\n",
    "class predictor_wrapper_class(object):\n",
    "    def __init__(self, predictor, outcome_name):\n",
    "        self.outcome_name = outcome_name\n",
    "        self.predictor = predictor\n",
    "    def predict_proba(self, x):\n",
    "        return self.predictor.predict_proba(x)[self.outcome_name].values\n",
    "    def predict(self, x):\n",
    "        return self.predictor.predict(x)[self.outcome_name].values\n",
    "predictor_wrapper=predictor_wrapper_class(predictor, outcome_name)\n",
    "\n",
    "droppeddata = data.iloc[:,:-10]\n",
    "droppeddata[outcome_name] = data[outcome_name]\n",
    "\n",
    "d = dice_ml.Data(dataframe=droppeddata,\n",
    "                      continuous_features=continuous_features,\n",
    "                      outcome_name=outcome_name)\n",
    "m = dice_ml.Model(model=predictor_wrapper, backend=\"sklearn\", model_type='regressor')\n",
    "dice_model = Dice(d, m, method=\"genetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f1c7b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CS Length': 0, 'BB Drop': 1, 'Stack': 1, 'SS E': 1, 'ST Angle': 1, 'BB OD': 1, 'TT OD': 1, 'HT OD': 1, 'DT OD': 1, 'CS OD': 1, 'SS OD': 1, 'ST OD': 1, 'CS F': 1, 'HT LX': 1, 'ST UX': 1, 'HT UX': 1, 'HT Angle': 1, 'HT Length': 0, 'ST Length': 0, 'BB Length': 0, 'Dropout Offset': 1, 'SSB OD': 1, 'CSB OD': 1, 'SSB Offset': 1, 'CSB Offset': 1, 'SS Z': 1, 'SS Thickness': 100000, 'CS Thickness': 100000, 'TT Thickness': 100000, 'BB Thickness': 100000, 'HT Thickness': 100000, 'ST Thickness': 100000, 'DT Thickness': 100000, 'DT Length': 0}\n"
     ]
    }
   ],
   "source": [
    "mads = d.get_mads(normalized=True)\n",
    "\n",
    "features_to_vary=[]\n",
    "for key in feature_weights.keys():\n",
    "    if key.endswith(\"Thickness\"):\n",
    "        feature_weights[key]=100000\n",
    "        features_to_vary.append(key)\n",
    "features_to_vary.append(\"Material\")\n",
    "print(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8173658b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:17<00:00, 17.38s/it]\n"
     ]
    }
   ],
   "source": [
    "queries = x[81:82]\n",
    "counterfactuals = dice_model.generate_counterfactuals(queries, \n",
    "                                                      total_CFs=5, \n",
    "                                                      desired_range=[3,5], \n",
    "                                                      features_to_vary=features_to_vary, \n",
    "                                                      proximity_weight=1, \n",
    "                                                      diversity_weight=1,\n",
    "                                                      feature_weights=feature_weights\n",
    "                                                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "611021ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>ST Angle</th>\n",
       "      <th>SS OD</th>\n",
       "      <th>ST UX</th>\n",
       "      <th>HT UX</th>\n",
       "      <th>ST Length</th>\n",
       "      <th>SSB OD</th>\n",
       "      <th>CSB OD</th>\n",
       "      <th>SS Thickness</th>\n",
       "      <th>CS Thickness</th>\n",
       "      <th>TT Thickness</th>\n",
       "      <th>BB Thickness</th>\n",
       "      <th>HT Thickness</th>\n",
       "      <th>ST Thickness</th>\n",
       "      <th>DT Thickness</th>\n",
       "      <th>Model Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>6.956542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Material  ST Angle   SS OD   ST UX   HT UX  ST Length    SSB OD    CSB OD  \\\n",
       "0    Steel      73.5  0.0155  0.0501  0.0197     0.2906  0.015849  0.017759   \n",
       "\n",
       "   SS Thickness  CS Thickness  TT Thickness  BB Thickness  HT Thickness  \\\n",
       "0       0.00092      0.009697      0.004546      0.004115      0.001094   \n",
       "\n",
       "   ST Thickness  DT Thickness  Model Mass  \n",
       "0      0.000653      0.005125    6.956542  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Material</th>\n",
       "      <th>ST Angle</th>\n",
       "      <th>SS OD</th>\n",
       "      <th>ST UX</th>\n",
       "      <th>HT UX</th>\n",
       "      <th>ST Length</th>\n",
       "      <th>SSB OD</th>\n",
       "      <th>CSB OD</th>\n",
       "      <th>SS Thickness</th>\n",
       "      <th>CS Thickness</th>\n",
       "      <th>TT Thickness</th>\n",
       "      <th>BB Thickness</th>\n",
       "      <th>HT Thickness</th>\n",
       "      <th>ST Thickness</th>\n",
       "      <th>DT Thickness</th>\n",
       "      <th>Model Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>4.103977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>3.734390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>4.620743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steel</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.007323</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>4.738657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanium</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>3.642193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Material  ST Angle  SS OD  ST UX  HT UX  ST Length    SSB OD    CSB OD  \\\n",
       "0     Steel      73.5  0.016   0.05   0.02       0.29  0.015849  0.017759   \n",
       "0     Steel      73.5  0.016   0.05   0.02       0.29  0.015849  0.017759   \n",
       "0     Steel      73.5  0.016   0.05   0.02       0.29  0.015849  0.017759   \n",
       "0     Steel      73.5  0.016   0.05   0.02       0.29  0.015849  0.017759   \n",
       "0  Titanium      73.5  0.016   0.05   0.02       0.29  0.015849  0.017759   \n",
       "\n",
       "   SS Thickness  CS Thickness  TT Thickness  BB Thickness  HT Thickness  \\\n",
       "0      0.000500      0.007474      0.002756      0.000500      0.000500   \n",
       "0      0.000952      0.000779      0.002397      0.003370      0.001379   \n",
       "0      0.003149      0.007936      0.000570      0.000708      0.001054   \n",
       "0      0.001809      0.004599      0.004079      0.007323      0.001183   \n",
       "0      0.000721      0.002475      0.004602      0.004503      0.005867   \n",
       "\n",
       "   ST Thickness  DT Thickness  Model Mass  \n",
       "0      0.001312      0.000976    4.103977  \n",
       "0      0.000563      0.003772    3.734390  \n",
       "0      0.000864      0.001893    4.620743  \n",
       "0      0.001662      0.000970    4.738657  \n",
       "0      0.000940      0.007076    3.642193  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim 1 Dropout X Disp.</th>\n",
       "      <th>Sim 1 Dropout Y Disp.</th>\n",
       "      <th>Sim 1 Bottom Bracket X Disp.</th>\n",
       "      <th>Sim 1 Bottom Bracket Y Disp.</th>\n",
       "      <th>Sim 2 Bottom Bracket Z Disp.</th>\n",
       "      <th>Sim 3 Bottom Bracket Y Disp.</th>\n",
       "      <th>Sim 3 Bottom Bracket X Rot.</th>\n",
       "      <th>Sim 1 Safety Factor</th>\n",
       "      <th>Sim 3 Safety Factor</th>\n",
       "      <th>Model Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.757286</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>6.956542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sim 1 Dropout X Disp.  Sim 1 Dropout Y Disp.  Sim 1 Bottom Bracket X Disp.  \\\n",
       "0               0.001643               0.001346                      0.001864   \n",
       "\n",
       "   Sim 1 Bottom Bracket Y Disp.  Sim 2 Bottom Bracket Z Disp.  \\\n",
       "0                      0.001327                      0.000319   \n",
       "\n",
       "   Sim 3 Bottom Bracket Y Disp.  Sim 3 Bottom Bracket X Rot.  \\\n",
       "0                      0.001932                     0.001267   \n",
       "\n",
       "   Sim 1 Safety Factor  Sim 3 Safety Factor  Model Mass  \n",
       "0             0.757286             0.582956    6.956542  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim 1 Dropout X Disp.</th>\n",
       "      <th>Sim 1 Dropout Y Disp.</th>\n",
       "      <th>Sim 1 Bottom Bracket X Disp.</th>\n",
       "      <th>Sim 1 Bottom Bracket Y Disp.</th>\n",
       "      <th>Sim 2 Bottom Bracket Z Disp.</th>\n",
       "      <th>Sim 3 Bottom Bracket Y Disp.</th>\n",
       "      <th>Sim 3 Bottom Bracket X Rot.</th>\n",
       "      <th>Sim 1 Safety Factor</th>\n",
       "      <th>Sim 3 Safety Factor</th>\n",
       "      <th>Model Mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>1.199091</td>\n",
       "      <td>1.608666</td>\n",
       "      <td>4.105883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.991185</td>\n",
       "      <td>1.034581</td>\n",
       "      <td>3.719593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>1.122589</td>\n",
       "      <td>1.132905</td>\n",
       "      <td>4.641598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>1.030027</td>\n",
       "      <td>1.189524</td>\n",
       "      <td>4.745330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.418932</td>\n",
       "      <td>0.167283</td>\n",
       "      <td>3.650079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sim 1 Dropout X Disp.  Sim 1 Dropout Y Disp.  Sim 1 Bottom Bracket X Disp.  \\\n",
       "0               0.005259               0.007542                      0.005965   \n",
       "0               0.002629               0.003178                      0.002811   \n",
       "0               0.005155               0.006507                      0.005414   \n",
       "0               0.004595               0.007558                      0.005387   \n",
       "0               0.003695               0.004762                      0.003638   \n",
       "\n",
       "   Sim 1 Bottom Bracket Y Disp.  Sim 2 Bottom Bracket Z Disp.  \\\n",
       "0                      0.003880                      0.000735   \n",
       "0                      0.001946                      0.000795   \n",
       "0                      0.003565                      0.000534   \n",
       "0                      0.003567                      0.000532   \n",
       "0                      0.002709                      0.000848   \n",
       "\n",
       "   Sim 3 Bottom Bracket Y Disp.  Sim 3 Bottom Bracket X Rot.  \\\n",
       "0                      0.004426                     0.004324   \n",
       "0                      0.002620                     0.002343   \n",
       "0                      0.003700                     0.002642   \n",
       "0                      0.003445                     0.001971   \n",
       "0                      0.003105                     0.002882   \n",
       "\n",
       "   Sim 1 Safety Factor  Sim 3 Safety Factor  Model Mass  \n",
       "0             1.199091             1.608666    4.105883  \n",
       "0             0.991185             1.034581    3.719593  \n",
       "0             1.122589             1.132905    4.641598  \n",
       "0             1.030027             1.189524    4.745330  \n",
       "0             0.418932             0.167283    3.650079  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# counterfactuals.visualize_as_dataframe(show_only_changes=True)\n",
    "for i in range(len(counterfactuals.cf_examples_list)):\n",
    "    cf_example = counterfactuals.cf_examples_list[i]\n",
    "    querydf = cf_example.test_instance_df.copy()\n",
    "    resdf = cf_example.final_cfs_df.copy()\n",
    "    dropcols=[]\n",
    "    for col in list(resdf.columns):\n",
    "        if resdf[col].values[0]==querydf[col].values[0]:\n",
    "            if resdf[col].nunique()==1:\n",
    "                dropcols.append(col)\n",
    "    resdf.drop(dropcols, axis=1, inplace=True)\n",
    "    display(querydf[resdf.columns])\n",
    "    display(resdf)\n",
    "    display(predictor.predict(cf_example.test_instance_df.copy()))\n",
    "    display(predictor.predict(cf_example.final_cfs_df.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05af25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "querydf[resdf.columns].to_csv(\"DICE_query.csv\")\n",
    "resdf.to_csv(\"DICE_res.csv\")\n",
    "predictor.predict(cf_example.test_instance_df.copy()).to_csv(\"DICE_query_perf.csv\")\n",
    "predictor.predict(cf_example.final_cfs_df.copy()).to_csv(\"DICE_res_perf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57e07f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SSB_Include CSB_Include  Material  CS Length  BB Drop   Stack   SS E  \\\n",
      "3935           1           1     Steel    0.43500    0.067  0.5849  0.050   \n",
      "288            0           0     Steel    0.34500    0.020  0.5656  0.045   \n",
      "712            0           0     Steel    0.39456    0.000  0.5656  0.045   \n",
      "769            0           0     Steel    0.44500    0.070  0.5656  0.045   \n",
      "1107           0           0     Steel    0.37000    0.040  0.5656  0.045   \n",
      "3292           1           1     Steel    0.40500    0.068  0.5106  0.020   \n",
      "1750           0           0     Steel    0.42500    0.069  0.5656  0.045   \n",
      "1397           0           0  Aluminum    0.40500    0.070  0.5656  0.045   \n",
      "4240           1           1  Titanium    0.42500    0.065  0.6551  0.050   \n",
      "3412           1           1  Titanium    0.41984    0.060  0.5656  0.045   \n",
      "\n",
      "       ST Angle  BB OD   TT OD  ...  CSB Offset   SS Z  SS Thickness  \\\n",
      "3935  74.000020  0.039  0.0286  ...        0.35  0.009      0.003268   \n",
      "288   73.500000  0.040  0.0287  ...        0.35  0.009      0.000920   \n",
      "712   72.500017  0.040  0.0286  ...        0.30  0.009      0.005628   \n",
      "769   71.999996  0.040  0.0286  ...        0.30  0.009      0.006424   \n",
      "1107  73.500000  0.040  0.0286  ...        0.30  0.009      0.002394   \n",
      "3292  74.000020  0.045  0.0286  ...        0.35  0.009      0.007447   \n",
      "1750  73.500000  0.040  0.0286  ...        0.30  0.009      0.001005   \n",
      "1397  74.000000  0.040  0.0286  ...        0.30  0.009      0.001973   \n",
      "4240  75.500024  0.040  0.0286  ...        0.35  0.009      0.002103   \n",
      "3412  74.000020  0.040  0.0286  ...        0.35  0.009      0.005021   \n",
      "\n",
      "      CS Thickness  TT Thickness  BB Thickness  HT Thickness  ST Thickness  \\\n",
      "3935      0.007107      0.000920      0.001789      0.009274      0.001945   \n",
      "288       0.009697      0.004546      0.004115      0.001094      0.000653   \n",
      "712       0.000904      0.008136      0.001819      0.001701      0.001721   \n",
      "769       0.006086      0.001138      0.002899      0.006510      0.000896   \n",
      "1107      0.002184      0.003487      0.002561      0.004248      0.000566   \n",
      "3292      0.001488      0.004851      0.004424      0.001988      0.004866   \n",
      "1750      0.000542      0.005514      0.001461      0.006826      0.006826   \n",
      "1397      0.000994      0.001847      0.003321      0.002586      0.001687   \n",
      "4240      0.001271      0.005889      0.001438      0.003666      0.009913   \n",
      "3412      0.007585      0.003726      0.006649      0.005065      0.001609   \n",
      "\n",
      "      DT Thickness  DT Length  \n",
      "3935      0.008850   0.663037  \n",
      "288       0.005125   0.595658  \n",
      "712       0.001890   0.614459  \n",
      "769       0.002068   0.645509  \n",
      "1107      0.000656   0.608560  \n",
      "3292      0.003696   0.614860  \n",
      "1750      0.006290   0.661146  \n",
      "1397      0.007590   0.653639  \n",
      "4240      0.000954   0.800688  \n",
      "3412      0.001244   0.659834  \n",
      "\n",
      "[10 rows x 37 columns]\n",
      "      Sim 1 Dropout X Disp.  Sim 1 Dropout Y Disp.  \\\n",
      "3935               0.009819               0.062947   \n",
      "288                0.001643               0.001346   \n",
      "712                0.003253               0.004913   \n",
      "769                0.018603               0.035780   \n",
      "1107               0.006102               0.010990   \n",
      "3292               0.008622               0.014861   \n",
      "1750               0.008715               0.014077   \n",
      "1397               0.027887               0.057975   \n",
      "4240               0.043410               0.073410   \n",
      "3412               0.033141               0.080401   \n",
      "\n",
      "      Sim 1 Bottom Bracket X Disp.  Sim 1 Bottom Bracket Y Disp.  \\\n",
      "3935                      0.017192                      0.015061   \n",
      "288                       0.001864                      0.001327   \n",
      "712                       0.003858                      0.002683   \n",
      "769                       0.021161                      0.018694   \n",
      "1107                      0.007319                      0.006556   \n",
      "3292                      0.008504                      0.007258   \n",
      "1750                      0.009710                      0.008032   \n",
      "1397                      0.033251                      0.029501   \n",
      "4240                      0.048957                      0.040222   \n",
      "3412                      0.036511                      0.040529   \n",
      "\n",
      "      Sim 2 Bottom Bracket Z Disp.  Sim 3 Bottom Bracket Y Disp.  \\\n",
      "3935                      0.000728                      0.004788   \n",
      "288                       0.000319                      0.001932   \n",
      "712                       0.001296                      0.002571   \n",
      "769                       0.000950                      0.007001   \n",
      "1107                      0.001265                      0.006994   \n",
      "3292                      0.000789                      0.003026   \n",
      "1750                      0.001740                      0.005133   \n",
      "1397                      0.002801                      0.010994   \n",
      "4240                      0.003582                      0.015464   \n",
      "3412                      0.001403                      0.013852   \n",
      "\n",
      "      Sim 3 Bottom Bracket X Rot.  Sim 1 Safety Factor  Sim 3 Safety Factor  \\\n",
      "3935                     0.001833             8.997803             0.785442   \n",
      "288                      0.001267             0.757286             0.582956   \n",
      "712                      0.003357             0.911333             0.782003   \n",
      "769                      0.002601             3.144331             1.328977   \n",
      "1107                     0.003766             1.196761             1.036714   \n",
      "3292                     0.002065             1.995147             1.028970   \n",
      "1750                     0.004005             2.028052             1.108650   \n",
      "1397                     0.006586             3.559912             1.042717   \n",
      "4240                     0.006561             1.740621             0.784598   \n",
      "3412                     0.004228             1.938148             0.935316   \n",
      "\n",
      "      Model Mass  \n",
      "3935    8.897923  \n",
      "288     6.956542  \n",
      "712     4.899960  \n",
      "769     5.886457  \n",
      "1107    4.246308  \n",
      "3292    6.912833  \n",
      "1750    6.693654  \n",
      "1397    2.278097  \n",
      "4240    4.616133  \n",
      "3412    4.459880  \n"
     ]
    }
   ],
   "source": [
    "print(x[80:90])\n",
    "print(predictor.predict(x[80:90]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "650ffafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SS Thickness',\n",
       " 'CS Thickness',\n",
       " 'TT Thickness',\n",
       " 'BB Thickness',\n",
       " 'HT Thickness',\n",
       " 'ST Thickness',\n",
       " 'DT Thickness',\n",
       " 'Material']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6462395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
